{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-29T05:31:02.215222Z","iopub.execute_input":"2022-04-29T05:31:02.215575Z","iopub.status.idle":"2022-04-29T05:31:02.246359Z","shell.execute_reply.started":"2022-04-29T05:31:02.215487Z","shell.execute_reply":"2022-04-29T05:31:02.245655Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torchvision\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import ToTensor\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data.dataloader import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:31:06.209565Z","iopub.execute_input":"2022-04-29T05:31:06.210291Z","iopub.status.idle":"2022-04-29T05:31:07.773110Z","shell.execute_reply.started":"2022-04-29T05:31:06.210256Z","shell.execute_reply":"2022-04-29T05:31:07.772156Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset = MNIST(root='data/', download=True, transform=ToTensor())","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:31:11.453606Z","iopub.execute_input":"2022-04-29T05:31:11.453877Z","iopub.status.idle":"2022-04-29T05:31:13.989262Z","shell.execute_reply.started":"2022-04-29T05:31:11.453848Z","shell.execute_reply":"2022-04-29T05:31:13.988225Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"len(dataset)\nimg, label = dataset[0]\nprint(img.shape, label)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:31:15.274555Z","iopub.execute_input":"2022-04-29T05:31:15.274834Z","iopub.status.idle":"2022-04-29T05:31:15.298389Z","shell.execute_reply.started":"2022-04-29T05:31:15.274806Z","shell.execute_reply":"2022-04-29T05:31:15.297776Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#displaying the image\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.imshow(img[0], cmap='gray') #pyplot expects the channel to be at the end so img[0] does that\n","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:31:18.269773Z","iopub.execute_input":"2022-04-29T05:31:18.270089Z","iopub.status.idle":"2022-04-29T05:31:18.459298Z","shell.execute_reply.started":"2022-04-29T05:31:18.270058Z","shell.execute_reply":"2022-04-29T05:31:18.458668Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#this function just creates training and validation data indices\n# received total length of dataset and percentage of data that will be in validation set\ndef split_indices(n, val_pct): \n    n_val = int(val_pct * n) # 60000 * .2 = 12000\n    idxs = np.random.permutation(n) # creates a permutation of n numbers i.e 60000\n    return idxs[n_val:], idxs[:n_val] # training data gets [12000: end] \n                                      # validation data gets [start: 12000] \n                                      # from a permutation of n","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:31:21.998606Z","iopub.execute_input":"2022-04-29T05:31:21.998925Z","iopub.status.idle":"2022-04-29T05:31:22.004331Z","shell.execute_reply.started":"2022-04-29T05:31:21.998891Z","shell.execute_reply":"2022-04-29T05:31:22.003411Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_indices, val_indices = split_indices(len(dataset), val_pct=0.2)\n\nprint(len(train_indices), len(val_indices))\nprint('Sample val indices: ', val_indices[:20])","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:31:23.870550Z","iopub.execute_input":"2022-04-29T05:31:23.870976Z","iopub.status.idle":"2022-04-29T05:31:23.878436Z","shell.execute_reply.started":"2022-04-29T05:31:23.870944Z","shell.execute_reply":"2022-04-29T05:31:23.877725Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# now we need data to be loaded according to the training and validation indicies\n\nbatch_size = 100\n\n#creating training sampler and training dataloader\ntrain_sampler = SubsetRandomSampler(train_indices)\ntrain_dl = DataLoader(dataset, batch_size, sampler=train_sampler)\n\n\n\n#creating validation sampler and validation dataloader\nvalid_sampler = SubsetRandomSampler(val_indices)\nvalid_dl = DataLoader(dataset, batch_size, sampler=valid_sampler)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:31:26.859059Z","iopub.execute_input":"2022-04-29T05:31:26.859854Z","iopub.status.idle":"2022-04-29T05:31:26.865279Z","shell.execute_reply.started":"2022-04-29T05:31:26.859805Z","shell.execute_reply":"2022-04-29T05:31:26.864463Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# ***Creating the MODEL***","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:31:32.945343Z","iopub.execute_input":"2022-04-29T05:31:32.945879Z","iopub.status.idle":"2022-04-29T05:31:32.949418Z","shell.execute_reply.started":"2022-04-29T05:31:32.945844Z","shell.execute_reply":"2022-04-29T05:31:32.948509Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class MnistModel(nn.Module):\n    def __init__(self, in_size, hidden_size, out_size):\n        super().__init__()\n        self.linear1 = nn.Linear(in_size, hidden_size)\n        self.linear2 = nn.Linear(hidden_size, out_size)\n        \n        \n    def forward(self, xb):\n        #Flattening the image tensors\n        xb = xb.view(xb.size(0), -1)\n        out = self.linear1(xb)\n        \n        out = F.relu(out)\n        out = self.linear2(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:33:49.511162Z","iopub.execute_input":"2022-04-29T05:33:49.511477Z","iopub.status.idle":"2022-04-29T05:33:49.518751Z","shell.execute_reply.started":"2022-04-29T05:33:49.511443Z","shell.execute_reply":"2022-04-29T05:33:49.517428Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"input_size = 784\nnum_classes = 10\n\nmodel = MnistModel(input_size, hidden_size=32, out_size= num_classes) #this one uses the super constructor function\n","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:45:26.243430Z","iopub.execute_input":"2022-04-29T05:45:26.243936Z","iopub.status.idle":"2022-04-29T05:45:26.260982Z","shell.execute_reply.started":"2022-04-29T05:45:26.243904Z","shell.execute_reply":"2022-04-29T05:45:26.260209Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for t in model.parameters():\n    print(t.shape)\n\n# it is stored in transpose form row becomes columns","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:45:28.764683Z","iopub.execute_input":"2022-04-29T05:45:28.765132Z","iopub.status.idle":"2022-04-29T05:45:28.770905Z","shell.execute_reply.started":"2022-04-29T05:45:28.765100Z","shell.execute_reply":"2022-04-29T05:45:28.770056Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for images, labels in train_dl:\n    print('images.shape ', images.shape)\n    outputs = model(images) #this one is calling the forward function with a batch of data\n    loss = F.cross_entropy(outputs, labels)\n    print('Loss:-', loss.item())\n    break\n\nprint('outputs.shape : ', outputs.shape)\nprint('Sample outputs :\\n', outputs[:2].data)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:52:45.721003Z","iopub.execute_input":"2022-04-29T05:52:45.721607Z","iopub.status.idle":"2022-04-29T05:52:45.801209Z","shell.execute_reply.started":"2022-04-29T05:52:45.721571Z","shell.execute_reply":"2022-04-29T05:52:45.800222Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# ****USING THE GPU****","metadata":{}},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T05:54:24.189495Z","iopub.execute_input":"2022-04-29T05:54:24.189820Z","iopub.status.idle":"2022-04-29T05:54:24.196040Z","shell.execute_reply.started":"2022-04-29T05:54:24.189784Z","shell.execute_reply":"2022-04-29T05:54:24.195322Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-04-29T06:04:30.356008Z","iopub.execute_input":"2022-04-29T06:04:30.356309Z","iopub.status.idle":"2022-04-29T06:04:30.361627Z","shell.execute_reply.started":"2022-04-29T06:04:30.356281Z","shell.execute_reply":"2022-04-29T06:04:30.360484Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-04-29T06:04:44.631393Z","iopub.execute_input":"2022-04-29T06:04:44.631711Z","iopub.status.idle":"2022-04-29T06:04:44.637521Z","shell.execute_reply.started":"2022-04-29T06:04:44.631678Z","shell.execute_reply":"2022-04-29T06:04:44.636678Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def to_device(data, device):\n    if isinstance(data, (list,tuple)):\n        return [to_device(x,device) for x in data]\n    \n    return data.to(device, non_blocking=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T06:12:54.298813Z","iopub.execute_input":"2022-04-29T06:12:54.299515Z","iopub.status.idle":"2022-04-29T06:12:54.304839Z","shell.execute_reply.started":"2022-04-29T06:12:54.299476Z","shell.execute_reply":"2022-04-29T06:12:54.303897Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"for images, labels in train_dl:\n    print(images.shape)\n    images = to_device(images, device)\n    print(images.device)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-04-29T06:13:11.152622Z","iopub.execute_input":"2022-04-29T06:13:11.153074Z","iopub.status.idle":"2022-04-29T06:13:11.341071Z","shell.execute_reply.started":"2022-04-29T06:13:11.153033Z","shell.execute_reply":"2022-04-29T06:13:11.340179Z"},"trusted":true},"execution_count":26,"outputs":[]}]}